{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c3225f",
   "metadata": {},
   "source": [
    "# 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8349333",
   "metadata": {},
   "source": [
    "# Install dependencies (run once per session)\n",
    "!pip install tensorflow pandas scikit-learn matplotlib seaborn --quiet\n",
    "\n",
    "# Standard imports for EV Battery Life Prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow/Keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"All packages installed and imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27707f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e89fad1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\prani\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "Python version: 3.12.5 (tags/v3.12.5:ff3bc82, Aug  6 2024, 20:45:27) [MSC v.1940 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1318520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ALL MODULES IMPORTED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TensorFlow/Keras imports  \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "print(\"✅ ALL MODULES IMPORTED SUCCESSFULLY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30cab397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TensorFlow/Keras imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# sklearn imports  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "print(\"All modules imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1915b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>start_time</th>\n",
       "      <th>ambient_temperature</th>\n",
       "      <th>battery_id</th>\n",
       "      <th>test_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Re</th>\n",
       "      <th>Rct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discharge</td>\n",
       "      <td>[2010.       7.      21.      15.       0.    ...</td>\n",
       "      <td>4</td>\n",
       "      <td>B0047</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00001.csv</td>\n",
       "      <td>1.6743047446975208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>impedance</td>\n",
       "      <td>[2010.       7.      21.      16.      53.    ...</td>\n",
       "      <td>24</td>\n",
       "      <td>B0047</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00002.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05605783343888099</td>\n",
       "      <td>0.20097016584458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charge</td>\n",
       "      <td>[2010.       7.      21.      17.      25.    ...</td>\n",
       "      <td>4</td>\n",
       "      <td>B0047</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00003.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>impedance</td>\n",
       "      <td>[2010    7   21   20   31    5]</td>\n",
       "      <td>24</td>\n",
       "      <td>B0047</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>00004.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05319185850921101</td>\n",
       "      <td>0.16473399914864734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discharge</td>\n",
       "      <td>[2.0100e+03 7.0000e+00 2.1000e+01 2.1000e+01 2...</td>\n",
       "      <td>4</td>\n",
       "      <td>B0047</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>00005.csv</td>\n",
       "      <td>1.5243662105099023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>impedance</td>\n",
       "      <td>[2010.       9.      30.       7.      36.    ...</td>\n",
       "      <td>24</td>\n",
       "      <td>B0055</td>\n",
       "      <td>247</td>\n",
       "      <td>7561</td>\n",
       "      <td>07561.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0968087979207628</td>\n",
       "      <td>0.15489738203707232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>discharge</td>\n",
       "      <td>[2010.       9.      30.       8.       8.    ...</td>\n",
       "      <td>4</td>\n",
       "      <td>B0055</td>\n",
       "      <td>248</td>\n",
       "      <td>7562</td>\n",
       "      <td>07562.csv</td>\n",
       "      <td>1.0201379996149256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>charge</td>\n",
       "      <td>[2010.      9.     30.      8.     48.     54.25]</td>\n",
       "      <td>4</td>\n",
       "      <td>B0055</td>\n",
       "      <td>249</td>\n",
       "      <td>7563</td>\n",
       "      <td>07563.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7563</th>\n",
       "      <td>discharge</td>\n",
       "      <td>[2010.       9.      30.      11.      50.    ...</td>\n",
       "      <td>4</td>\n",
       "      <td>B0055</td>\n",
       "      <td>250</td>\n",
       "      <td>7564</td>\n",
       "      <td>07564.csv</td>\n",
       "      <td>0.9907591663373165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7564</th>\n",
       "      <td>charge</td>\n",
       "      <td>[2010.       9.      30.      12.      31.    ...</td>\n",
       "      <td>4</td>\n",
       "      <td>B0055</td>\n",
       "      <td>251</td>\n",
       "      <td>7565</td>\n",
       "      <td>07565.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7565 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type                                         start_time  \\\n",
       "0     discharge  [2010.       7.      21.      15.       0.    ...   \n",
       "1     impedance  [2010.       7.      21.      16.      53.    ...   \n",
       "2        charge  [2010.       7.      21.      17.      25.    ...   \n",
       "3     impedance                    [2010    7   21   20   31    5]   \n",
       "4     discharge  [2.0100e+03 7.0000e+00 2.1000e+01 2.1000e+01 2...   \n",
       "...         ...                                                ...   \n",
       "7560  impedance  [2010.       9.      30.       7.      36.    ...   \n",
       "7561  discharge  [2010.       9.      30.       8.       8.    ...   \n",
       "7562     charge  [2010.      9.     30.      8.     48.     54.25]   \n",
       "7563  discharge  [2010.       9.      30.      11.      50.    ...   \n",
       "7564     charge  [2010.       9.      30.      12.      31.    ...   \n",
       "\n",
       "      ambient_temperature battery_id  test_id   uid   filename  \\\n",
       "0                       4      B0047        0     1  00001.csv   \n",
       "1                      24      B0047        1     2  00002.csv   \n",
       "2                       4      B0047        2     3  00003.csv   \n",
       "3                      24      B0047        3     4  00004.csv   \n",
       "4                       4      B0047        4     5  00005.csv   \n",
       "...                   ...        ...      ...   ...        ...   \n",
       "7560                   24      B0055      247  7561  07561.csv   \n",
       "7561                    4      B0055      248  7562  07562.csv   \n",
       "7562                    4      B0055      249  7563  07563.csv   \n",
       "7563                    4      B0055      250  7564  07564.csv   \n",
       "7564                    4      B0055      251  7565  07565.csv   \n",
       "\n",
       "                Capacity                   Re                  Rct  \n",
       "0     1.6743047446975208                  NaN                  NaN  \n",
       "1                    NaN  0.05605783343888099  0.20097016584458333  \n",
       "2                    NaN                  NaN                  NaN  \n",
       "3                    NaN  0.05319185850921101  0.16473399914864734  \n",
       "4     1.5243662105099023                  NaN                  NaN  \n",
       "...                  ...                  ...                  ...  \n",
       "7560                 NaN   0.0968087979207628  0.15489738203707232  \n",
       "7561  1.0201379996149256                  NaN                  NaN  \n",
       "7562                 NaN                  NaN                  NaN  \n",
       "7563  0.9907591663373165                  NaN                  NaN  \n",
       "7564                 NaN                  NaN                  NaN  \n",
       "\n",
       "[7565 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"metadata.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46a119",
   "metadata": {},
   "source": [
    "# 2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee7f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>ambient_temperature</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Re</th>\n",
       "      <th>Rct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6743047446975208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>impedance</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05605783343888099</td>\n",
       "      <td>0.20097016584458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charge</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>impedance</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05319185850921101</td>\n",
       "      <td>0.16473399914864734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5243662105099023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>impedance</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0968087979207628</td>\n",
       "      <td>0.15489738203707232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0201379996149256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>charge</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7563</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9907591663373165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7564</th>\n",
       "      <td>charge</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7565 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type  ambient_temperature            Capacity                   Re  \\\n",
       "0     discharge                    4  1.6743047446975208                  NaN   \n",
       "1     impedance                   24                 NaN  0.05605783343888099   \n",
       "2        charge                    4                 NaN                  NaN   \n",
       "3     impedance                   24                 NaN  0.05319185850921101   \n",
       "4     discharge                    4  1.5243662105099023                  NaN   \n",
       "...         ...                  ...                 ...                  ...   \n",
       "7560  impedance                   24                 NaN   0.0968087979207628   \n",
       "7561  discharge                    4  1.0201379996149256                  NaN   \n",
       "7562     charge                    4                 NaN                  NaN   \n",
       "7563  discharge                    4  0.9907591663373165                  NaN   \n",
       "7564     charge                    4                 NaN                  NaN   \n",
       "\n",
       "                      Rct  \n",
       "0                     NaN  \n",
       "1     0.20097016584458333  \n",
       "2                     NaN  \n",
       "3     0.16473399914864734  \n",
       "4                     NaN  \n",
       "...                   ...  \n",
       "7560  0.15489738203707232  \n",
       "7561                  NaN  \n",
       "7562                  NaN  \n",
       "7563                  NaN  \n",
       "7564                  NaN  \n",
       "\n",
       "[7565 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['start_time','battery_id','test_id','uid','filename'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075bc41",
   "metadata": {},
   "source": [
    "### filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d51cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prani\\AppData\\Local\\Temp\\ipykernel_29096\\574227293.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Re'].fillna(df['Re'].mean(), inplace=True)\n",
      "C:\\Users\\prani\\AppData\\Local\\Temp\\ipykernel_29096\\574227293.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Rct'].fillna(df['Rct'].mean(), inplace=True)\n",
      "C:\\Users\\prani\\AppData\\Local\\Temp\\ipykernel_29096\\574227293.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Capacity'].fillna(df['Capacity'].mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>ambient_temperature</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Re</th>\n",
       "      <th>Rct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.674305</td>\n",
       "      <td>-4.976500e+11</td>\n",
       "      <td>1.055903e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>impedance</td>\n",
       "      <td>24</td>\n",
       "      <td>1.326543</td>\n",
       "      <td>5.605783e-02</td>\n",
       "      <td>2.009702e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.326543</td>\n",
       "      <td>-4.976500e+11</td>\n",
       "      <td>1.055903e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>impedance</td>\n",
       "      <td>24</td>\n",
       "      <td>1.326543</td>\n",
       "      <td>5.319186e-02</td>\n",
       "      <td>1.647340e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.524366</td>\n",
       "      <td>-4.976500e+11</td>\n",
       "      <td>1.055903e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>impedance</td>\n",
       "      <td>24</td>\n",
       "      <td>1.326543</td>\n",
       "      <td>9.680880e-02</td>\n",
       "      <td>1.548974e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.020138</td>\n",
       "      <td>-4.976500e+11</td>\n",
       "      <td>1.055903e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>charge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.326543</td>\n",
       "      <td>-4.976500e+11</td>\n",
       "      <td>1.055903e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7563</th>\n",
       "      <td>discharge</td>\n",
       "      <td>4</td>\n",
       "      <td>0.990759</td>\n",
       "      <td>-4.976500e+11</td>\n",
       "      <td>1.055903e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7564</th>\n",
       "      <td>charge</td>\n",
       "      <td>4</td>\n",
       "      <td>1.326543</td>\n",
       "      <td>-4.976500e+11</td>\n",
       "      <td>1.055903e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7565 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type  ambient_temperature  Capacity            Re           Rct\n",
       "0     discharge                    4  1.674305 -4.976500e+11  1.055903e+12\n",
       "1     impedance                   24  1.326543  5.605783e-02  2.009702e-01\n",
       "2        charge                    4  1.326543 -4.976500e+11  1.055903e+12\n",
       "3     impedance                   24  1.326543  5.319186e-02  1.647340e-01\n",
       "4     discharge                    4  1.524366 -4.976500e+11  1.055903e+12\n",
       "...         ...                  ...       ...           ...           ...\n",
       "7560  impedance                   24  1.326543  9.680880e-02  1.548974e-01\n",
       "7561  discharge                    4  1.020138 -4.976500e+11  1.055903e+12\n",
       "7562     charge                    4  1.326543 -4.976500e+11  1.055903e+12\n",
       "7563  discharge                    4  0.990759 -4.976500e+11  1.055903e+12\n",
       "7564     charge                    4  1.326543 -4.976500e+11  1.055903e+12\n",
       "\n",
       "[7565 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Re', 'Rct', and 'Capacity' to numeric, invalid parsing will be set to NaN\n",
    "df['Re'] = pd.to_numeric(df['Re'], errors='coerce')\n",
    "df['Rct'] = pd.to_numeric(df['Rct'], errors='coerce')\n",
    "df['Capacity'] = pd.to_numeric(df['Capacity'], errors='coerce')\n",
    "\n",
    "\n",
    "# Fill missing values in 'Re', 'Rct', and 'Capacity' with their respective means\n",
    "df['Re'].fillna(df['Re'].mean(), inplace=True)\n",
    "df['Rct'].fillna(df['Rct'].mean(), inplace=True)\n",
    "df['Capacity'].fillna(df['Capacity'].mean(), inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3d1a7",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18cd754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['type'] = label_encoder.fit_transform(df['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7e1c8",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb750467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6052, 4)\n",
      "X_test shape: (1513, 4)\n"
     ]
    }
   ],
   "source": [
    "# Features (X) - All columns except 'ambient_temperature'\n",
    "X = df.drop(columns=['ambient_temperature'])\n",
    "\n",
    "# Target (y) - 'ambient_temperature' column\n",
    "y = df['ambient_temperature']\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the split data\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42275587",
   "metadata": {},
   "source": [
    "# Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "426d6bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X_train: \n",
      "[[1.00000000e+00 5.02450122e-01 9.99999999e-01 1.98111482e-10]\n",
      " [5.00000000e-01 4.55998175e-01 0.00000000e+00 1.00000000e+00]\n",
      " [5.00000000e-01 3.60527766e-02 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 5.02450122e-01 0.00000000e+00 1.00000000e+00]\n",
      " [5.00000000e-01 5.35874070e-01 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data, then transform the test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the scaled data\n",
    "print(f'Scaled X_train: \\n{X_train_scaled[:5]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c76c3e",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b5ddf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,433</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,433\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,433</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,433\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the ANN model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with 64 units and ReLU activation\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "\n",
    "# Add Dropout layer with 0.2 rate (20% dropout)\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Second hidden layer with 32 units and ReLU activation\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add another Dropout layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer with 1 unit (for regression output), using a linear activation\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Compile the model with Adam optimizer and Mean Squared Error loss (for regression)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04a51e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 279.9216 - val_loss: 62956.2617\n",
      "Epoch 2/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116.6876 - val_loss: 39209.7969\n",
      "Epoch 3/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 113.0202 - val_loss: 20655.4570\n",
      "Epoch 4/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111.4128 - val_loss: 9326.9004\n",
      "Epoch 5/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107.9353 - val_loss: 5118.5801\n",
      "Epoch 6/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106.5935 - val_loss: 2635.9573\n",
      "Epoch 7/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104.4474 - val_loss: 1904.8015\n",
      "Epoch 8/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.1506 - val_loss: 753.3512\n",
      "Epoch 9/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101.6367 - val_loss: 410.7618\n",
      "Epoch 10/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101.5333 - val_loss: 158.5944\n",
      "Epoch 11/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 100.6236 - val_loss: 142.8440\n",
      "Epoch 12/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99.2123 - val_loss: 113.2928\n",
      "Epoch 13/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98.8717 - val_loss: 111.5132\n",
      "Epoch 14/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97.2223 - val_loss: 119.1685\n",
      "Epoch 15/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98.1220 - val_loss: 129.6999\n",
      "Epoch 16/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97.8891 - val_loss: 124.6999\n",
      "Epoch 17/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96.9826 - val_loss: 163.2877\n",
      "Epoch 18/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96.3088 - val_loss: 186.0568\n",
      "Epoch 19/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96.1549 - val_loss: 177.1578\n",
      "Epoch 20/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95.1457 - val_loss: 200.0585\n",
      "Epoch 21/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95.0700 - val_loss: 216.9208\n",
      "Epoch 22/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95.8429 - val_loss: 247.6904\n",
      "Epoch 23/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96.7211 - val_loss: 332.7522\n",
      "Epoch 24/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.4096 - val_loss: 379.0329\n",
      "Epoch 25/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.4197 - val_loss: 392.4897\n",
      "Epoch 26/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.8384 - val_loss: 404.5322\n",
      "Epoch 27/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95.4322 - val_loss: 446.4144\n",
      "Epoch 28/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.0583 - val_loss: 529.0153\n",
      "Epoch 29/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.5014 - val_loss: 676.8705\n",
      "Epoch 30/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.6462 - val_loss: 711.5381\n",
      "Epoch 31/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.8096 - val_loss: 744.5466\n",
      "Epoch 32/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.0066 - val_loss: 739.6384\n",
      "Epoch 33/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.0608 - val_loss: 728.0383\n",
      "Epoch 34/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.3434 - val_loss: 747.7587\n",
      "Epoch 35/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.0093 - val_loss: 923.2507\n",
      "Epoch 36/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.2563 - val_loss: 996.4150\n",
      "Epoch 37/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.5052 - val_loss: 882.0100\n",
      "Epoch 38/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.3659 - val_loss: 935.8889\n",
      "Epoch 39/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.2043 - val_loss: 1131.3889\n",
      "Epoch 40/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.2371 - val_loss: 1338.5759\n",
      "Epoch 41/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.2411 - val_loss: 1255.0082\n",
      "Epoch 42/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.9411 - val_loss: 1320.3440\n",
      "Epoch 43/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.4150 - val_loss: 1264.5216\n",
      "Epoch 44/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.1958 - val_loss: 1423.7733\n",
      "Epoch 45/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.5507 - val_loss: 1387.3921\n",
      "Epoch 46/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.5823 - val_loss: 1344.8143\n",
      "Epoch 47/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.5860 - val_loss: 1419.9843\n",
      "Epoch 48/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.2406 - val_loss: 1289.1995\n",
      "Epoch 49/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.4641 - val_loss: 1275.3239\n",
      "Epoch 50/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.4731 - val_loss: 1323.2067\n",
      "Epoch 51/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.4808 - val_loss: 1308.8389\n",
      "Epoch 52/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.0557 - val_loss: 1365.5618\n",
      "Epoch 53/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.1099 - val_loss: 1333.9292\n",
      "Epoch 54/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.4195 - val_loss: 1414.7543\n",
      "Epoch 55/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.6397 - val_loss: 1286.6101\n",
      "Epoch 56/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.5186 - val_loss: 1274.7018\n",
      "Epoch 57/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.4892 - val_loss: 1345.0569\n",
      "Epoch 58/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.9381 - val_loss: 1287.1561\n",
      "Epoch 59/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.1171 - val_loss: 1200.5118\n",
      "Epoch 60/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.4807 - val_loss: 1304.8644\n",
      "Epoch 61/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.6764 - val_loss: 1093.4603\n",
      "Epoch 62/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.9573 - val_loss: 1236.8104\n",
      "Epoch 63/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.8330 - val_loss: 1326.1400\n",
      "Epoch 64/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.4270 - val_loss: 1325.8478\n",
      "Epoch 65/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.4960 - val_loss: 1244.0428\n",
      "Epoch 66/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 91.5588 - val_loss: 1450.1282\n",
      "Epoch 67/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.0857 - val_loss: 1388.0762\n",
      "Epoch 68/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.3158 - val_loss: 1346.3511\n",
      "Epoch 69/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.4803 - val_loss: 1175.7480\n",
      "Epoch 70/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.6559 - val_loss: 938.8203\n",
      "Epoch 71/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.8191 - val_loss: 995.2943\n",
      "Epoch 72/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.6680 - val_loss: 933.2208\n",
      "Epoch 73/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.7197 - val_loss: 973.2920\n",
      "Epoch 74/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.4971 - val_loss: 1010.8848\n",
      "Epoch 75/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.9750 - val_loss: 1009.1921\n",
      "Epoch 76/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.1331 - val_loss: 1051.8911\n",
      "Epoch 77/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.2955 - val_loss: 988.6250\n",
      "Epoch 78/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.5910 - val_loss: 843.8771\n",
      "Epoch 79/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.7248 - val_loss: 802.4451\n",
      "Epoch 80/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.4899 - val_loss: 930.1276\n",
      "Epoch 81/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.1078 - val_loss: 879.6502\n",
      "Epoch 82/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.2718 - val_loss: 1020.2130\n",
      "Epoch 83/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.8353 - val_loss: 834.1072\n",
      "Epoch 84/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.8025 - val_loss: 763.8226\n",
      "Epoch 85/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.2043 - val_loss: 667.1974\n",
      "Epoch 86/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.8921 - val_loss: 739.9521\n",
      "Epoch 87/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.5700 - val_loss: 731.2878\n",
      "Epoch 88/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.3531 - val_loss: 765.1956\n",
      "Epoch 89/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.9654 - val_loss: 723.8876\n",
      "Epoch 90/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.3044 - val_loss: 812.7180\n",
      "Epoch 91/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.7183 - val_loss: 774.8477\n",
      "Epoch 92/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.6941 - val_loss: 708.8268\n",
      "Epoch 93/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.6466 - val_loss: 810.5984\n",
      "Epoch 94/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.0325 - val_loss: 810.0581\n",
      "Epoch 95/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.1231 - val_loss: 829.7130\n",
      "Epoch 96/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.0693 - val_loss: 860.6317\n",
      "Epoch 97/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.8992 - val_loss: 885.9887\n",
      "Epoch 98/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.2689 - val_loss: 797.3399\n",
      "Epoch 99/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.5647 - val_loss: 779.7159\n",
      "Epoch 100/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.9118 - val_loss: 766.6646\n",
      "Epoch 101/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.7681 - val_loss: 720.9359\n",
      "Epoch 102/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.2187 - val_loss: 726.0887\n",
      "Epoch 103/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.6133 - val_loss: 727.2986\n",
      "Epoch 104/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.2343 - val_loss: 735.4243\n",
      "Epoch 105/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.9880 - val_loss: 883.4526\n",
      "Epoch 106/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.3129 - val_loss: 780.1992\n",
      "Epoch 107/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.5944 - val_loss: 976.0565\n",
      "Epoch 108/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.0500 - val_loss: 924.4114\n",
      "Epoch 109/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.8934 - val_loss: 912.3940\n",
      "Epoch 110/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.2506 - val_loss: 896.9355\n",
      "Epoch 111/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.8293 - val_loss: 816.3477\n",
      "Epoch 112/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.0595 - val_loss: 905.9073\n",
      "Epoch 113/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.2476 - val_loss: 932.4486\n",
      "Epoch 114/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90.2911 - val_loss: 984.5172\n",
      "Epoch 115/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.9867 - val_loss: 893.8082\n",
      "Epoch 116/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.6841 - val_loss: 1056.2695\n",
      "Epoch 117/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.5340 - val_loss: 995.1659\n",
      "Epoch 118/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.1744 - val_loss: 1253.0576\n",
      "Epoch 119/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.5540 - val_loss: 1320.3773\n",
      "Epoch 120/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.5532 - val_loss: 1577.3202\n",
      "Epoch 121/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.6404 - val_loss: 1739.7261\n",
      "Epoch 122/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.8778 - val_loss: 1448.1527\n",
      "Epoch 123/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.9047 - val_loss: 2020.7616\n",
      "Epoch 124/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.7341 - val_loss: 1786.7782\n",
      "Epoch 125/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.3450 - val_loss: 1852.4681\n",
      "Epoch 126/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.0743 - val_loss: 2009.9041\n",
      "Epoch 127/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.5257 - val_loss: 1944.7098\n",
      "Epoch 128/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.5640 - val_loss: 1536.7854\n",
      "Epoch 129/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87.7547 - val_loss: 2116.1287\n",
      "Epoch 130/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.1314 - val_loss: 2333.7236\n",
      "Epoch 131/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.4086 - val_loss: 1976.9028\n",
      "Epoch 132/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.1943 - val_loss: 1777.3650\n",
      "Epoch 133/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.3196 - val_loss: 2172.0493\n",
      "Epoch 134/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.9357 - val_loss: 2747.9126\n",
      "Epoch 135/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.0452 - val_loss: 2690.1919\n",
      "Epoch 136/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.2686 - val_loss: 2635.2395\n",
      "Epoch 137/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.3507 - val_loss: 2549.4543\n",
      "Epoch 138/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.2600 - val_loss: 2706.4922\n",
      "Epoch 139/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.0774 - val_loss: 3003.7092\n",
      "Epoch 140/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.9845 - val_loss: 2944.6670\n",
      "Epoch 141/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.3867 - val_loss: 3152.3596\n",
      "Epoch 142/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.3964 - val_loss: 3421.9722\n",
      "Epoch 143/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87.4569 - val_loss: 2519.9573\n",
      "Epoch 144/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87.3692 - val_loss: 3416.6924\n",
      "Epoch 145/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87.7074 - val_loss: 2535.0312\n",
      "Epoch 146/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.2514 - val_loss: 3021.9832\n",
      "Epoch 147/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.3606 - val_loss: 2887.5886\n",
      "Epoch 148/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.5651 - val_loss: 2256.5217\n",
      "Epoch 149/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.0157 - val_loss: 2555.4446\n",
      "Epoch 150/150\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.0531 - val_loss: 2411.3779\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data, using the test data for validation\n",
    "history = model.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841483a7",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99647c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install matplotlib first (run this once)\n",
    "!pip install matplotlib\n",
    "\n",
    "# Then import and use matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your plotting code\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52762190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2411.3779\n",
      "Mean Squared Error on test set: 2411.3779296875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "mse = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Print the Mean Squared Error (MSE)\n",
    "print(f'Mean Squared Error on test set: {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf44260",
   "metadata": {},
   "source": [
    "# Prediction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9570160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_battery_life(type_discharge, Capacity, Re, Rct, label_encoder, scaler, model):\n",
    "    \n",
    "    # Encode the categorical feature\n",
    "    type_discharge_encoded = label_encoder.transform([type_discharge])[0]\n",
    "    \n",
    "    # Prepare the input feature vector\n",
    "    X_input = np.array([[type_discharge_encoded,Capacity, Re, Rct]])\n",
    "    \n",
    "    # Scale the input features using the same scaler\n",
    "    X_input_scaled = scaler.transform(X_input)\n",
    "    \n",
    "    # Predict the battery life (ambient_temperature)\n",
    "    predicted_battery_life = model.predict(X_input_scaled)\n",
    "    \n",
    "    return predicted_battery_life[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a563971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Predicted Battery Life: [25.391468]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the function\n",
    "type_discharge = 'discharge'  # Example input for type\n",
    "Capacity = 1.674305           # Example numeric value\n",
    "Re = -4.976500e+11            # Example numeric value\n",
    "Rct = 1.055903e+12            # Example numeric value\n",
    "\n",
    "# Call the prediction function\n",
    "predicted_battery_life = predict_battery_life(type_discharge, Capacity, Re, Rct, label_encoder, scaler, model)\n",
    "\n",
    "print(f\"Predicted Battery Life: {predicted_battery_life}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df321a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted Battery Life: [355.79886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the function with new input values\n",
    "type_discharge = 'charge'  # New input for type\n",
    "Capacity = 20.5            # Example numeric value for Capacity\n",
    "Re = -2.983215e+11         # Example numeric value for Re\n",
    "Rct = 1.223456e+12         # Example numeric value for Rct\n",
    "\n",
    "# Call the prediction function with these new values\n",
    "predicted_battery_life = predict_battery_life(type_discharge, Capacity, Re, Rct, label_encoder, scaler, model)\n",
    "\n",
    "# Print the predicted battery life\n",
    "print(f\"Predicted Battery Life: {predicted_battery_life}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe255174",
   "metadata": {},
   "source": [
    "# Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33bffaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model, scaler, and label encoder to disk\n",
    "with open('battery_life_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "with open('label_encoder.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoder, le_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "931ab703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"battery_life_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
